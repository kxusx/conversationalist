# üéØ CONVERSATIONALIST - DEMO SCRIPT FOR JUDGES
**Goal**: Show judges how AI glasses + memory augmentation can transform networking

---

## üé¨ PRE-DEMO CHECKLIST (5 mins before)

### Technical Setup
- [ ] Server running: `.venv\Scripts\python.exe capture_service/server.py`
- [ ] Open browser to `http://localhost:9876` (share screen/project this)
- [ ] Glasses connected and sending frames (check "Glasses Active" pill is green)
- [ ] Microphone working (check VAD responds when you speak)
- [ ] Redis connected (green pill showing profile count)
- [ ] **Check System Logs**: Should show "‚úÖ Redis connected" and profile counts
- [ ] Have 2-3 people ready to play "strangers" (or use photos on phone pointed at glasses)

### Pre-Seed a Profile (Optional but Recommended)
Before the demo, have the system already know ONE person to show instant recognition:

**Person A - Pre-loaded Contact:**
```python
# Run this once before demo:
python
>>> from person_store import store_new_person
>>> import numpy as np
>>> fake_embedding = np.random.rand(128).tolist()
>>> details = {
...     "name": "Sarah Chen",
...     "company": "Stripe",
...     "role": "Product Manager",
...     "interests": ["API design", "developer tools"],
...     "personal_facts": ["Has a corgi named Biscuit", "Marathon runner"],
...     "topics_discussed": ["API rate limiting", "payment infrastructure"],
...     "follow_ups": ["Promised intro to their VC friend"],
...     "memorable_quotes": []
... }
>>> person_id = store_new_person(fake_embedding, details)
>>> print(f"Seeded: {person_id}")
```

---

## üé≠ THE DEMO FLOW (3-5 minutes)

### **Act 1: The Problem** (30 seconds)
**You (to judges):**
> "Imagine you're at a conference. You meet 50 people in one day. Two weeks later, 
> you see someone and think 'I know you... but from where?' This is embarrassing. 
> We built Conversationalist to solve this."

**Point to screen:** Shows live video feed from glasses.

---

### **Act 2: First Encounter - Profile Building** (90 seconds)

**Person B appears** (look at them through glasses)

**Person B says:**
> "Hi! I'm Alex Martinez. Nice to meet you."

**You respond naturally:**
> "Hey Alex! What brings you here?"

**Person B:**
> "I'm a founding engineer at a climate tech startup called CarbonZero. 
> We're building carbon capture tech. I'm actually a rock climber in my spare time - 
> just got back from Yosemite last weekend."

**You:**
> "That's awesome! We should definitely catch up about your tech stack sometime."

**‚èØÔ∏è PAUSE - Point to UI:**
- Transcript appears in real-time ‚úÖ
- Person card may appear if face detected ‚úÖ
- **Key point:** "The system just learned about Alex - name, company, interests, all stored."
- Show Redis count increment in header

---

### **Act 3: The Magic - Instant Memory Recall** (90 seconds)

**Walk away briefly (5 seconds)**

**Person A (Sarah - pre-seeded) appears** (look at them)

**üéØ THIS IS THE WOW MOMENT:**
> UI shows:
> - Person card pops up with "Sarah Chen"
> - Smart Trigger appears: "Sarah from Stripe - you discussed API rate limiting, she has a corgi named Biscuit, promised an intro to her VC friend"

**You (reading the trigger):**
> "Hey Sarah! How's Biscuit doing? And did you get a chance to make that intro to your VC friend?"

**Person A (confused acting):**
> "Wait, how did you remember that?!"

**‚èØÔ∏è PAUSE - Point to UI:**
> "See this? The system instantly retrieved Sarah's profile from our vector database. 
> It matched her face in milliseconds and gave me a memory cue. This is like having 
> a perfect memory for every conversation."

---

### **Act 4: Memory Evolution** (60 seconds)

**Person B (Alex) returns**

**Person B:**
> "Hey! Just wanted to mention - we're actually hiring. Looking for ML engineers if you know anyone."

**You:**
> "Definitely! I'll keep that in mind."

**‚èØÔ∏è PAUSE - Point to UI:**
- Person card updates with Alex's info
- Encounter count increments
- New follow-up added to profile
- System logs show "Updated profile: Alex Martinez"

**You (to judges):**
> "Notice the encounter count went from 1 to 2. The system is building a rich profile 
> across multiple conversations. In two weeks, when I see Alex again, I'll remember 
> they mentioned hiring."

---

### **Act 5: The Tech Stack** (45 seconds)

**Point to Pipeline Visualization:**

> "Here's what's happening under the hood:
> 
> 1. **Weave Telemetry** - Every interaction logged for Q-LoRA fine-tuning
> 2. **Redis VSS** - [point to count] We now have X profiles stored with face embeddings
> 3. **Llama 3.1 70B** - Generates these memory triggers and extracts structured data
> 4. **Q-LoRA Training** - Collecting data to fine-tune our own model
> 
> All of this runs locally. Your conversations stay private."

---

### **Act 6: The Vision** (30 seconds)

**You (closing pitch):**
> "This is just the beginning. Imagine:
> - Never forgetting a name or face again
> - Perfect memory of every conversation
> - Automatic follow-ups and relationship management
> - Training personalized models that learn YOUR networking style
> 
> We're augmenting human memory with AI. This is Conversationalist."

---

## üî• BACKUP PLANS (If Things Go Wrong)

### If glasses aren't sending video:
‚úÖ **Say:** "While the glasses reconnect, let me show you a recorded demo..."
- Have a pre-recorded video ready OR
- Use your phone camera pointed at faces

### If Redis is down:
‚úÖ **Say:** "Our vector database is cloud-hosted. Let me show you the local cache..."
- Show the `observe_redis.py` output pre-captured as screenshot

### If no face detection:
‚úÖ **Say:** "Even without faces, the system still works beautifully..."
- Demo with transcript-only interaction
- Show how it extracts names from conversation

### If VAD is too sensitive:
‚úÖ Speak clearly and pause between sentences
‚úÖ Pre-record the conversation audio and play it back

---

## üéØ KEY TALKING POINTS FOR JUDGES

### Technical Innovation
- "First real-time memory augmentation system with smart glasses"
- "Combines face recognition, LLM extraction, and vector search"
- "All privacy-preserving - runs locally, you own your data"

### Market Opportunity
- "Networking is a $X billion TAM - everyone needs to remember people better"
- "B2B: Sales teams, recruiters, executives"
- "B2C: Anyone who attends conferences, events, or has ADHD/memory issues"

### Competitive Moat
- "DeepFace + Redis VSS + Llama 3.1 + Q-LoRA - full stack we built"
- "Real-time pipeline optimized for wearables"
- "Training data flywheel - gets better with use"

### Traction (if asked)
- "X profiles already in our database from testing"
- "System successfully recalled details from conversations held weeks ago"
- "Integrated with Weave for complete observability"

---

## üí° PRO TIPS

1. **Rehearse once** before the actual demo
2. **Have the UI visible** the entire time - judges love seeing real-time updates
3. **Slow down** when pointing at specific UI elements
4. **Make eye contact** with judges when making key points
5. **Be ready to answer**:
   - "How does privacy work?" ‚Üí Local processing, user owns data
   - "What if it fails?" ‚Üí Graceful degradation, works without faces
   - "How accurate is it?" ‚Üí [cite your testing metrics]
   - "Can I try it?" ‚Üí Absolutely! (have extra glasses ready)

---

## üèÜ JUDGING CRITERIA COVERAGE

| Criteria | How We Nail It |
|----------|----------------|
| **Innovation** | First real-time memory augmentation with smart glasses |
| **Technical Execution** | Live working demo, full stack, production-ready |
| **Market Potential** | Universal problem (everyone forgets faces), huge TAM |
| **Team** | Shipped complex ML + hardware integration in 36 hours |
| **Presentation** | Live interactive demo > slides any day |

---

## üìä EXPECTED JUDGE REACTIONS

‚úÖ **"Wow, that actually worked!"** ‚Üí Smile, explain the tech
‚úÖ **"But what about privacy?"** ‚Üí Emphasize local processing
‚úÖ **"How does this scale?"** ‚Üí Redis Cloud, W&B Inference API
‚úÖ **"I need this!"** ‚Üí You've won. Collect their info. 

---

## üé§ OPENING LINE (OPTIONAL)

**Confident approach:**
> "Hi judges! Quick question - do you remember the name of the first person you met today? 
> [pause] Exactly. Let me show you how we're solving that with AI glasses."

**Then start the demo immediately.**

---

## ‚è±Ô∏è TIMING BREAKDOWN

- Problem statement: 30s
- First encounter (teach): 90s
- Memory recall (wow moment): 90s
- Second encounter (evolution): 60s
- Tech stack explanation: 45s
- Vision/closing: 30s
- **Total: ~5 minutes + Q&A**

---

**Good luck! You've got this! üöÄ**
